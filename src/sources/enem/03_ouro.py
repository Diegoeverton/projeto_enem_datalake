"""
03_ouro.py  |  Fonte: ENEM  |  Camada: Ouro
--------------------------------------------
Responsabilidade:
    LÃª os dados limpos da Prata e gera tabelas analÃ­ticas agregadas (Camada Ouro).
    Processa um ano por vez para evitar estouro de memÃ³ria.

Tabelas geradas (acumuladas de todos os anos):
    - media_notas_por_uf_ano   : MÃ©dia das 5 notas por UF e por Ano
    - distribuicao_perfil      : Candidatos por Faixa EtÃ¡ria, Sexo e RaÃ§a
    - ranking_redacao_por_uf   : Nota mÃ©dia de redaÃ§Ã£o por UF (excluindo ausentes)

Entrada : /app/data_lake/prata/enem/ano=<ANO>/*.parquet
SaÃ­da   : /app/data_lake/ouro/enem/<nome_tabela>/*.parquet

Como rodar individualmente:
    docker exec spark_enem bash /app/run.sh --fonte enem --etapa ouro
"""

import os
import sys

sys.path.insert(0, "/app/src")
from spark_utils import get_spark_session

from pyspark.sql.functions import col, avg, count, lit, round as spark_round


# â”€â”€ Caminhos â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
PASTA_PRATA = "/app/data_lake/prata/enem"
PASTA_OURO  = "/app/data_lake/ouro/enem"

NOTAS       = ["NU_NOTA_CN", "NU_NOTA_CH", "NU_NOTA_LC", "NU_NOTA_MT", "NU_NOTA_REDACAO"]
COLS_PERFIL = ["TP_FAIXA_ETARIA", "TP_SEXO", "TP_COR_RACA"]


def criar_camada_ouro():
    spark = get_spark_session("ENEM_Ouro", memory="2g")

    print("\nğŸ¥‡ [OURO] Iniciando agregaÃ§Ãµes ENEM â†’ Camada Ouro...")
    print(f"   Fonte Prata : {PASTA_PRATA}")
    print(f"   Destino Ouro: {PASTA_OURO}\n")

    if not os.path.exists(PASTA_PRATA):
        print("âŒ Camada Prata nÃ£o encontrada. Execute 02_prata.py primeiro.")
        spark.stop()
        return

    anos_disponiveis = sorted(
        [d for d in os.listdir(PASTA_PRATA) if d.startswith("ano=")]
    )

    if not anos_disponiveis:
        print("âš ï¸  Nenhuma partiÃ§Ã£o encontrada na Prata. Execute 02_prata.py primeiro.")
        spark.stop()
        return

    # Acumuladores: lista de DataFrames por tabela (um por ano)
    dfs_media   = []
    dfs_perfil  = []
    dfs_ranking = []

    # â”€â”€ Processa um ano por vez para nÃ£o explodir a memÃ³ria â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    for diretorio_ano in anos_disponiveis:
        ano = diretorio_ano.split("=")[1]
        caminho_leitura = os.path.join(PASTA_PRATA, diretorio_ano)
        print(f"ğŸ” Processando ano {ano}...")

        df = spark.read.parquet(caminho_leitura)

        # Adiciona coluna 'ano' explÃ­cita (nÃ£o depende da partiÃ§Ã£o do path)
        df = df.withColumn("ano", lit(ano))

        # â”€â”€ TABELA 1: MÃ©dia das notas por UF â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        notas_presentes = [c for c in NOTAS if c in df.columns]
        if notas_presentes and "SG_UF_PROVA" in df.columns:
            agg_media = [
                spark_round(avg(col(c)), 2).alias(c.replace("NU_NOTA_", "MEDIA_"))
                for c in notas_presentes
            ]
            df_media_ano = df.groupBy("ano", "SG_UF_PROVA").agg(*agg_media)
            dfs_media.append(df_media_ano)

        # â”€â”€ TABELA 2: DistribuiÃ§Ã£o de perfil â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        cols_perfil_presentes = [c for c in COLS_PERFIL if c in df.columns]
        if cols_perfil_presentes:
            df_perfil_ano = (
                df.groupBy("ano", *cols_perfil_presentes)
                  .agg(count("*").alias("TOTAL_CANDIDATOS"))
            )
            dfs_perfil.append(df_perfil_ano)

        # â”€â”€ TABELA 3: Ranking de redaÃ§Ã£o por UF â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if "NU_NOTA_REDACAO" in df.columns and "SG_UF_PROVA" in df.columns:
            df_ranking_ano = (
                df.filter(col("NU_NOTA_REDACAO") > 0)
                  .groupBy("ano", "SG_UF_PROVA")
                  .agg(
                      spark_round(avg("NU_NOTA_REDACAO"), 2).alias("MEDIA_REDACAO"),
                      count("*").alias("TOTAL_PARTICIPANTES"),
                  )
            )
            dfs_ranking.append(df_ranking_ano)

        print(f"âœ… Ano {ano} agregado.\n")

    # â”€â”€ Une todos os anos e grava as tabelas finais â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("ğŸ’¾ Gravando tabelas finais na Camada Ouro...\n")

    if dfs_media:
        df_final_media = dfs_media[0]
        for df_ in dfs_media[1:]:
            df_final_media = df_final_media.union(df_)
        df_final_media.orderBy("ano", "SG_UF_PROVA") \
                      .write.mode("overwrite") \
                      .parquet(os.path.join(PASTA_OURO, "media_notas_por_uf_ano"))
        print(f"âœ… media_notas_por_uf_ano â†’ {df_final_media.count():,} linhas")

    if dfs_perfil:
        df_final_perfil = dfs_perfil[0]
        for df_ in dfs_perfil[1:]:
            df_final_perfil = df_final_perfil.union(df_)
        df_final_perfil.orderBy("ano") \
                       .write.mode("overwrite") \
                       .parquet(os.path.join(PASTA_OURO, "distribuicao_perfil"))
        print(f"âœ… distribuicao_perfil â†’ {df_final_perfil.count():,} linhas")

    if dfs_ranking:
        df_final_ranking = dfs_ranking[0]
        for df_ in dfs_ranking[1:]:
            df_final_ranking = df_final_ranking.union(df_)
        df_final_ranking.orderBy("ano", col("MEDIA_REDACAO").desc()) \
                        .write.mode("overwrite") \
                        .parquet(os.path.join(PASTA_OURO, "ranking_redacao_por_uf"))
        print(f"âœ… ranking_redacao_por_uf â†’ {df_final_ranking.count():,} linhas")

    print("\nğŸ [OURO] Todas as tabelas analÃ­ticas geradas com sucesso!")
    spark.stop()


if __name__ == "__main__":
    criar_camada_ouro()
